name: hisup
encoder:
    type: HRNet48v2
    pretrained: True

    input_size: 512
    input_height: ${.input_size}
    input_width: ${.input_size}
    
    output_size: 128
    output_height: ${.output_size}
    output_width: ${.output_size}
    
    out_feature_channels: 256


fusion: patch_concat # or feature_concat

# optimization

# training
batch_size: 32
start_epoch: 0
num_epochs: 100
milestone: 0
learning_rate: 4e-4
weight_decay: 1e-4

loss_weights:
    loss_joff: 0.25    # joff  regression
    loss_jloc: 8.0     # jloc  classification
    loss_mask: 1.0
    loss_afm : 0.1
    loss_remask : 1.0


defaults:
    - lidar_encoder: pointpillars


# the following values are adapted such that the PointPillars layer can be used as a drop in for the 
# patch_embed layer of the vision transformer - vit_small_patch8_224_dino (specified in cfg.model.encoder)
lidar_encoder:
    in_voxel_size:
        x: 2
        y: 2

    max_num_points_per_voxel: 4 # this should be something around points_per_tile / num_voxels_per_tile

    max_num_voxels:
        train: 65536 # 256**2
        test: 65536 # 256**2

    out_voxel_width: 256
    out_voxel_height: 256

    out_dim: 64