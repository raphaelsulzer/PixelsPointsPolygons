name: hisup
encoder:
    type: HRNet48v2
    pretrained: True
    checkpoint_file: ${...host.data_root}/hrnetv2_w48_imagenet_pretrained.pth

    in_size: 512
    in_height: ${.in_size}
    in_width: ${.in_size}
    
    out_feature_size: 128
    out_feature_height: ${.out_feature_size}
    out__featurewidth: ${.out_feature_size}
    
    out_feature_channels: 256


fusion: patch_concat # or feature_concat

# optimization

# training
batch_size: 16
start_epoch: 0
num_epochs: 100
milestone: 0
learning_rate: 1e-4
weight_decay: 1e-4

loss_weights:
    loss_joff: 0.25    # joff  regression
    loss_jloc: 8.0     # jloc  classification
    loss_mask: 1.0
    loss_afm : 0.1
    loss_remask : 1.0


defaults:
    - lidar_encoder: pointpillars


lidar_encoder:
    # in theory, these are values in [m]. However, because I scale the LiDAR tile to match image coordinates, these are [m]*s, i.e. here s=224/56
    # in fact, one voxel is always 0.25m x 0.25m, so the standard voxel size is 2m x 2m
    in_voxel_size:
        x: 8
        y: 8

    max_num_points_per_voxel: 128 # this should be something around points_per_tile / num_voxels_per_tile, however, I find that half of that value is enough

    max_num_voxels: # here: (512/8)**2
        train: 4096 # 256**2
        test: 4096 # 256**2

    out_width: ${.encoder.out_width}
    out_height: ${.encoder.out_height}

    out_feature_channels: ${.encoder.out_feature_channels}


augmentations:
    - D4
    - Resize
    - ColorJitter
    - GaussNoise